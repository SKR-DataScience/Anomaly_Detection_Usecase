
# 이상탐지 모델 비교를 위한 실험설계, 모델 선택법

> ## 학습목표
    - 모델의 성능 개선을 위한 실험 설계
    - 서로 다른 모델간의 성능을 통계적인 방법으로 비교하고 모델을 비교/선택


</br>

> ## 실험의 목적/요구사항 
   - 재현 가능한 실험 → 실험 자체의 결론이 다르게 나와선 안 됨
   - 새로운 데이터에 대한 성능 측정
   - 변인에 따른 유의미한 효과 파악
   - 모델 성능을 객관적으로 평가
   - 미래에 새로운 데이터가 들어오는 시나리오에서 모델이 어떻게 동작할지 기존 데이터만으로 모사할 수 있어야 함
- 서로 다른 모델을 객관적으로 비교할 수 있어야 함
- 실험에 랜덤성이 존재하는 경우 이 실험의 결과가 우연인지 아닌지 통계적인 근거를 제시할 수 있어야 함


</br>

> ## 실험의 목적/요구사항 
1. 단일 모델의 평가 -
   데이터 유형에 따른 단일 모델 평가 방법
   1) 시간 순서가 없는 데이터셋 → 데이터 셔플해야 함 
      - K-FOLD CROSS VALIDATION
        - 일반적으로 많이 사용
        - Traninig set에서 보지 못한 데이터에 대한 예측 성능을 평가
        - 다양한 데이터에 대한 예측 성능을 평가
        - train/valid/test 3개의 셋을 두기도 함
      - Leave-one-out cross validation
        - 1개의 샘플에 대해 평가
        - 데이터가 부족한 경우 활용, but 머신러닝/딥러닝 프로젝트에서 잘 활용하지는 않음

    <br>

    2) 시간 순서가 있는 데이터셋 → 미래 참조의 오류를 조심해야 함
       - 미래 참조 오류: 미래 데이터를 학습해 과거를 예측하는 오류. 미래의 데이터에 과거의 정보가 이미 반영되어 있는 데이터가 있다. 
         - ex) 기온 데이터 → 그냥 shuffling해버리면 미래 데이터를 학습하여 과거 데이터를 맞추게 되는 꼴
       - 따라서, time series nested cross validation을 사용 → 미래 참조 오류 방지
         - 테스트셋은 항상 시간 순서상 마지막에 와야 함
         - 시간상 그 앞의 데이터를 활용해 모델을 학습하고 평가하는 방식
         - training 데이터를 어떻게 활용하냐에 따라
            - expanding window → train 데이터 전부 활용
            - sliding window → train 데이터 일부만 사용. 모델의 복잡도가 낮거나 최신 경향을 반영하는 게 중요한 경우 sliding window 사용하는 게 더 합리적
   
</br>

> ## 여러 모델간의 평가
1. 실험 계획법 (Design of experiment)
    - 효율적인 실험 방법을 설계하고 결과를 제대로 분석하는 것을 목적으로 하는 통계학의 응용 분야
  
2. 머신러닝 실험에서
    - 주어진 데이터셋에 대한 두 가지 모델의 평가를 고려할 때, 어떤 모델을 선택할 것인가?
        - 모델을 평가하는 성능 지표가 높은 모델을 선택
    - 지표의 차이가 실제적인 모델 성능의 차이인지, 아니면 우연의 결과인지 어떻게 알 수 있는가?
        - 실험계획법을 통해 여러 요인을 비교하고, 가설검정을 통해 통계적으로 유의미한 차이가 있는지 확인

<br>

3. 실험 계획법의 실시
    1. 실험목적의 설정
        - 실험을 통해 무엇을 비교하려 하는지
            
            ex) 변수1,2,3… 중 어떤 변수를 활용하는 것이 모델의 성능을 향상시키는지
            
            ex) 모델A, B 중 어떤 모델을 활용하는 것이 더 높은 성능을 내는지
            
            ex) 모델을 구성하는 어떤 파라미터 A를 50으로 설정할건지, 100으로 설정할건지
            
    2. 특성치의 선택
        - 위 예시에서는 변수, 모델의 선택
  
    3. 인자와 인자수준의 선택
        
        ex) 변수: 변수1, 2, 3
        
        ex) 모델: 모델A, 모델B
        
        ex) 파라미터A: 50, 100, 150

<br>

4. 실험군과 대조군
    1. 대조군
        - 앞으로 모든 실험에서 기준이 되는 그룹
        - 아무런 조치도 취하지 않은 집단. 외부변수들은 영향을 줄 수 없도록 제한해야 함
        
            ex) 모델A, 변수1, 파라미터A=50이 베이스라인이라면
        
            대조군 = (모델A, 변수1, 파라미터A=50)이 됨
        
    
     2. 실험군
    
         - 조치를 취함으로써 특정 인자가 대상에 미치는 영향을 알아보기 위한 집단
          - 예시
           - 모델B의 효과를 알아보기 위한 대조군 = (모델B, 변수1, 파라미터A=50) → 비교하고 싶은 ‘모델’만 변경하고 나머지는 베이스라인과 동일하게 그대로
          - 그 외의 다른 변인들을 통제하여 엄밀한 결과를 얻거나 다수의 변인을 동시에 적용하여 전체 실험 수를 줄이기도 함

<br>


5. T-test와 P-value
    1. T-test
        - 머신러닝 실험에는 랜덤성이 존재
            
            ex) 데이터셋을 섞는 경우, 랜덤시드에 따라 train/valid set이 달라질 수 있고, 모델의 최종 평가지표도 다르게 나타남
            
            ex) gradient descent 계열의 최적화를 사용할 경우, 여러 요인으로 인해 다른 로컬 미니멈에 도달할 수 있음.
            
            ex) 모델 A 실험결과 → 평균 0.7, 분산 5.6을 가짐 → 각 값들을 분포로 그림
            
            모델 B 실험결과(10회 실시, 랜덤성이 있는 모델) → 각 값들을 분포로 그림
            
            →  두 분포 중 더 오른쪽에 있는 분포가 성능이 더 좋은 것이므로, 오른쪽 모델을 선택. 단순히 두 모델의 평균 값만 가지고 어떤 모델이 더 좋다 나쁘다를 이야기하기는 어려움. 그래서 T-test와 P-value가 필요한 것

</br>

> ## 자원을 고려한 여러 최적화 방법
1. Grid Search
      - 인자A(가로) 인자B(세로)의 서로 가능한 모든 조합에 대해 실험 진행
      - 모든 조합을 조사할 수 있으니, 많은 비용 소요
  
<br>

2. Random Search
      - 각 인자수준에 대해 랜덤하게 탐색 진행
      - 빠른 시간 내에 최적값에 도달할 가능성 있으나, 반대로 최적값에 도달하지 못할 가능성도 존재함

<br>

[아래 방법은 프로젝트를 고도화해가거나, 탐색해야 하는 범위가 너무 넓을 때 활용하는 방법들]

3. Bayesian Optimization → 최적해를 빠르게 찾는 것에 집중
      - Y를 추정하는 black-box function f(x)를 생성
      - 실험계획법은 모든 실험을 수행하고 사후에 결과를 분석,
    - bayesian optimization은 어떤 x를 넣었을 때 나오는 y값을 가지고, 관측값이 나올 때마다 y를 추정하는 어떤 black box function을 생성 
      - 실험을 거듭해가면서 black box function의 성능이 좋아짐. 앞에서는 실험결과가 나와야 y 값을 알 수 있었다면 bayesian은 어떤 함수를 통해서 y값을 추정하게 됨. 이때 하이퍼파라미터를 업데이트 해가면서 최소/최대값을 탐색. 
        - 알고리즘에서 다음에 어떤 x값을 넣어야 좋은 y값을 기대할 수 있는지 추천해주기 때문에 그리드/랜덤서치보다 조금 더 효율적인 탐색을 할 가능성이 있음

<br>

4. 유전 알고리즘(Genetic algorithm)
      - 우리가 관심있는 하이퍼파라미터들의 무작위한 조합을 유전자로 표현
      - 생물의 진화를 모방하여 세대를 거듭해가며 가장 좋은 하이퍼파라미터들끼리의 접합, 돌연변이를 통해 최적해를 찾는 방법
  
<br>

5. 담금질 기법(Simulated Annealing) → 사실은 담금질이 아닌 풀림으로 번역되어야 맞음
      - 풀림(Annealing): 금속재료를 가열한 다음 조금씩 냉각해 결정을 성장시켜 그 결함을 줄이는 작업
      - 담금질을 할 때, 처음에는 고온에서 물질을 가격하여 큰 변성을 주지만, 온도가 내려가면서 점점 적게 변화되는 것을 모방한 방법
      - 초기에는 파라미터를 크게 바꿔가며 넓은 영역을 탐색해가다가 반복이 쌓일수록 어느 영역에 도달해 파라미터의 변화량을 줄여가면서 세밀하게 최적해를 찾는 방법
